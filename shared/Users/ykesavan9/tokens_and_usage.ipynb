{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q python-dotenv openai azure-identity tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-06-01\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing a prompt\n",
    " Demonstrates how to encode a prompt into tokens, count the total number of tokens, and decode them back into words using the tiktoken library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 9\n",
      "Tokens : [79207, 5377, 15836, 2532, 374, 3331, 16528, 1457, 0]\n",
      "Words :  ['Azure', ' Open', 'AI', ' service', ' is', ' General', ' Available', ' now', '!']\n"
     ]
    }
   ],
   "source": [
    "encoding=tiktoken.encoding_for_model(GPT_MODEL)\n",
    "prompt = \"Azure OpenAI service is General Available now!\"\n",
    "tokens = encoding.encode(prompt)\n",
    "\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Tokens :', tokens)\n",
    "print('Words : ', [encoding.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Token usage in \n",
    "\n",
    "## The CompletionUsage output provides detailed information about token usage in a request:\n",
    "| Token Type         | Description                                                                 |\n",
    "|--------------------|-----------------------------------------------------------------------------|\n",
    "| completion_tokens  | Number of tokens used in the generated completion.                          |\n",
    "| prompt_tokens      | Number of tokens used in the input prompt.                                  |\n",
    "| total_tokens       | Total number of tokens used in the request (sum of prompt tokens and completion tokens). |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== ANSWER #1 ==============================\n",
      "That's great news! Azure OpenAI service provides a powerful set of tools for developers and data scientists to build, train, and deploy cutting-edge AI models and applications. With access to powerful hardware and software resources, Azure OpenAI service makes it easier than ever to leverage the latest advances in deep learning\n",
      "============================== ANSWER #2 ==============================\n",
      "That's great to know! Can you tell me more about it?\n",
      "CompletionUsage(completion_tokens=74, prompt_tokens=28, total_tokens=102, completion_tokens_details=None)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-06-01\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n",
    "prompt = \"Azure OpenAI service is General Available now!\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=GPT_MODEL,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\": prompt}],\n",
    "    max_tokens=60,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "# Shows 2 results\n",
    "print('='*30, 'ANSWER #1', '='*30)\n",
    "print(response.choices[0].message.content)\n",
    "print('='*30, 'ANSWER #2', '='*30)\n",
    "print(response.choices[1].message.content)\n",
    "\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
