{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q python-dotenv openai azure-identity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"AOAI_ENDPOINT\"))\n",
    "print(os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2023-05-15\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\")\n",
    "    )\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "with open('azure-oai-models.json', 'w') as file:\n",
    "    models_dict = [model.__dict__ for model in models]\n",
    "    json.dump(models_dict, file)\n",
    "\n",
    "for model in models:\n",
    "    print(\"ID:\", model.id)\n",
    "    print(\"Current status:\", model.lifecycle_status)\n",
    "    print(\"Model capabilities:\", model.capabilities)\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n",
    "\n",
    "prompt_startphrase = \"Suggest three names for a new pet salon business. The generated name ideas should evoke positive emotions and the following key features: Professional, friendly, Personalized Service.\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    prompt=prompt_startphrase,\n",
    "    temperature=0.7,\n",
    "    max_tokens=100,\n",
    "    #best_of=5,\n",
    "    n=3,\n",
    "    stop=None)\n",
    "\n",
    "responsetext = response.choices[0].text\n",
    "\n",
    "print(\"Prompt:\" + prompt_startphrase + \"\\nResponse:\" + responsetext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "# This model name is what you chose when you deployed the model in Azure OpenAI\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n",
    "\n",
    "prompt_startphrase = \"Suggest three names for a new pet salon business. The generated name ideas should evoke positive emotions and the following key features: Professional, friendly, Personalized Service.\"\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=GPT_MODEL,  \n",
    "    prompt=prompt_startphrase,\n",
    "    temperature=0.8,\n",
    "    max_tokens=100,\n",
    "    logit_bias={\n",
    "        30026:-100,\n",
    "        81:-100,\n",
    "        9330:-100,\n",
    "        808:-100,\n",
    "        42114:-100,\n",
    "        1308:-100, \n",
    "        3808:-100,\n",
    "        502:-100,\n",
    "        322:-100}\n",
    "    )  \n",
    "  \n",
    "responsetext = response.choices[0].text\n",
    "print(responsetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "# This model name is what you chose when you deployed the model in Azure OpenAI\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},\n",
    "        {\"role\":\"user\",\"content\":\"Hello world\"},\n",
    "        {\"role\":\"assistant\",\"content\":\"Hello! How can I assist you today?\"},\n",
    "        {\"role\":\"user\",\"content\":\"I want to know more about pets and why dogs are good for humans?\"}],\n",
    "    temperature=0.8,\n",
    "    max_tokens=800,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AOAI_ENDPOINT\"),\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    api_key=os.getenv(\"AOAI_KEY\"))\n",
    "\n",
    "# This model name is what you chose when you deployed the model in Azure OpenAI\n",
    "GPT_MODEL = \"gpt-35-turbo\"\n",
    "\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "max_response_tokens = 250\n",
    "token_limit = 4096\n",
    "conversation = []\n",
    "conversation.append(system_message)\n",
    "\n",
    "def num_tokens_from_messages(messages):\n",
    "    encoding= tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4           # every message follows <im_start>{role/name}\\n{content}<im_end>\\n\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":     # if there's a name, the role is omitted\n",
    "                num_tokens += -1  # role is always required and always 1 token\n",
    "    num_tokens += 2               # every reply is primed with <im_start>assistant\n",
    "    return num_tokens\n",
    "\n",
    "print(\"I am a helpful assistant. I can talk about pets and salons. What would you like to talk about?\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\")     \n",
    "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
    "    conv_history_tokens = num_tokens_from_messages(conversation)\n",
    "\n",
    "    while conv_history_tokens + max_response_tokens >= token_limit:\n",
    "        del conversation[1] \n",
    "        conv_history_tokens = num_tokens_from_messages(conversation)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=conversation,\n",
    "        temperature=0.8,\n",
    "        max_tokens=max_response_tokens)\n",
    "\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content})\n",
    "    print(\"\\n\" + response.choices[0].message.content)\n",
    "    print(\"(Tokens used: \" + str(response.usage.total_tokens)  + \")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
